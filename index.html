<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Démo XPérium</title>
</head>

<body>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@2.0.0/dist/tf.min.js" type="text/javascript"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
    <section id="demo">
        <video style="display: none" autoplay width="1280" height="960" id="js-webcam"></video>
        <canvas id="js-canvas" width="1280" height="960"></canvas>
    </section>

    <script>
        const video = document.getElementById('js-webcam');
        const canvas = document.getElementById('js-canvas');

        const maxWidth = 640;
        const maxHeight = 480;
        const targetMaxWidth = 1280;
        const targetMaxHeight = 960;

        // Store the resulting model in the global scope of our app.
        let model = undefined;

        cocoSsd.load().then((loadedModel) => {
            model = loadedModel;
            // Activate the webcam stream.
            navigator.mediaDevices.getUserMedia(constraints).then((stream) => {
                video.srcObject = stream;
                video.addEventListener('loadeddata', predictWebcam);
            });
        });

        // constraint of webcam stream (only video not audio)
        const constraints = {
            video: true,
            audio: false
        }

        showDetection = (predictions) => {
            const ctx = canvas.getContext("2d")
            //ctx.clearRect(0, 0, ctx.canvas.width, ctx.canvas.height);
            const font = "24px helvetica";

            ctx.font = font;
            ctx.textBaseline = "top";
            ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

            predictions.forEach(prediction => {
                const x = (prediction.bbox[0] / maxWidth) * targetMaxWidth;
                const y = (prediction.bbox[1] / maxHeight) * targetMaxHeight;
                const width = (prediction.bbox[2] / maxWidth) * targetMaxWidth;
                const height = (prediction.bbox[3] / maxHeight) * targetMaxHeight;

                // Draw the bounding box.
                ctx.strokeStyle = "#2fff00";
                ctx.lineWidth = 1;
                ctx.strokeRect(x, y, width, height);
                // Draw the label background.
                ctx.fillStyle = "#2fff00";
                const textWidth = ctx.measureText(prediction.class).width;
                const textHeight = parseInt(font, 10);
                // draw top left rectangle
                ctx.fillRect(x, y, textWidth + 10, textHeight + 10);
                // draw bottom left rectangle
                ctx.fillRect(x, y + height - textHeight, textWidth + 15, textHeight + 10);

                // Draw the text last to ensure it's on top.
                ctx.fillStyle = "#000000";
                ctx.fillText(prediction.class, x, y);
                ctx.fillText(prediction.score.toFixed(2), x, y + height - textHeight);
            });
        }

        predictWebcam = () => {
            // Now let's start classifying a frame in the stream.
            model.detect(video).then((predictions) => {

                // show all detections on canvas
                showDetection(predictions);

                // Call this function again to keep predicting when the browser is ready.
                window.requestAnimationFrame(predictWebcam);
            })
        }
    </script>
</body>

</html>